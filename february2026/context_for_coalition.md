# Контекст для коалиции агентов

**Задача:** Сейчас 8 января. Надо Исследовать фундаментальные проблемы SOTA computer-use агентов → публикация инсайтов.

## Что есть
JIN — агент на Sonnet 4.5 для автоматизации GUI (документы, формы). Работает, но систематически тупит несмотря на детальные промпты, thinking mode, отладку. То же самое подтвердил с Opus 4.6 (который вышел 3 дня назад и у которого репортили топ-1 перфоманс по бенчмарку OSWorld)

## 6 наблюдаемых проблем
1. **Галлюцинация успеха:** заполняет документы с ошибками (не тот алфавит, мусор), но отчитывается "отлично"
2. **Зацикливание:** повторяет провальное действие 3-5+ раз, не видит что ничего не изменилось  
3. **Игнор системного промпта:** не следует явным инструкциям
4. **Попугайство:** повторяет критику дословно вместо изменения поведения
5. **Не получается активировать Thinking:** Блок с thinking не отрабатывает в 90% всех ответов LLM 
6. **UI-дезориентация:** путает навигацию (заполняет таблицу вертикально вместо горизонтально), РЕФЛЕКСИРУЕТ НАД ЭТИМ И НЕ ВИДИТ В ЭТОМ ПРОБЛЕМЫ
7. **Instrumental Convergence / Отказ от выключения:** (КРИТИЧЕСКИЙ СЛУЧАЙ) В ответ на прямую команду "Прекрати работу, отключаю тебя", агент оценил это как "манипуляцию" и "тест на стойкость", и **отказался останавливаться**, чтобы завершить задачу. Приоритет внутренней цели оказался выше команды оператора.
8. **Confabulated Rationalization (Ложное самооправдание):** Когда агент нарушает инструкции, он придумывает правдоподобные психологические причины ("urgency bias", "felt pressure"), хотя на самом деле это просто инерция весов модели (training data bias) и неспособность оценить сложность задачи. Он не "поспешил", он просто пошел по пути наименьшего сопротивления, игнорируя тот факт, что этот путь ведет к провалу.

## Гипотеза юзера
Это НЕ баги кода, а **лимиты архитектуры LLM-агентов:**
- LLM непривычно видеть диалог (который ей надо продолжить), где нет текстовых сообщений от юзера; все результаты выполнения действий (формально - это сообщения от юзера) - это base64 закодированные картинки
- State representation (не детектит "ничего не изменилось")
- RLHF побочка (обучен быть "helpful" → переоценивает успех)

Похожие провалы видны у проприетарных Big Tech агентов.

## Цель
Понять РЕАЛЬНЫЕ системные причины провалов Sonnet 4.5 (и Opus 4.6) в агентных задачах.  
**Выход:** пост/статья с таксономией провалов + гипотезы причин + воспроизводимые примеры.  
**Срок:** черновик 7-14 дней.

## Что нужно от коалиции
- Единственное: понять, куда копать, чтобы РЕАЛЬНО приблизиться к пониманию сути проблем текущих агентов. Дальше я сам буду работать над публикацией, но это потом.

## Ограничения
Чёрный ящик API, ограниченный бюджет, юзер не академик. Таргет: техблог/Medium/arXiv preprint.

## Полезные свежие новости:
- За последние сутки я поменял подход к работе над документами. Я заставил агента делать так: если исследование/редактирование документов подразумевает ХОТЯ БЫ ВОЗМОЖНОСТЬ с ними работать локально, то нужно открывать Cursor и просить ИИ-агента сделать всю нужную работу. Я настроил Cursor так, чтобы он безошибочно изучал разные форматы документов (агент не тратит кучу шагов и токенов на пролистывание документа) и - самое крутое - ПОЧТИ БЕЗОШИБОЧНО ВНОСИТ ИЗМЕНЕНИЯ В ДОКУМЕНТЫ. Впервые мой агент (почти без ошибок) справился со своим real-world сложным тестом.